you you you you you
Знания компьютерных алгоритмов на Computer Science говорят, что нет звука. Так, давайте еще раз.
Говорят, звук должен быть. Тогда давайте еще раз. Всем привет, меня зовут Иван. Последние 6 лет я занимаюсь задачей машинного обучения. Сейчас они уже невозможны, по сути, без знания компьютерных алгоритмов, computer science, algorithms. Поэтому сегодня мы разберем одну из тем, конкретно на графы. Надеюсь, это будет вам интересным. Немножко о себе. Я сейчас работаю в компании ShareChat на позиции машинолог-инженер. До этого работал чуть больше года в «Революте». Это, наверное, некоторым будет известен банк в Англии, в Великобритании. А до этого большая часть времени прожил в «Яндексе», около 5 лет занимался там задачами поиска и рекламы. Это была наша вводная часть. Давайте начнем тогда. Так, одну секунду. Так, да, давайте продолжим. Вспомним, что такое граф. Граф — это не что иное, как набор вершин и ребер. Обозначает сейчас буквы «Ж» и «В» — это вершины, «Е» — это ребра. Пока что ничего сложного. Просто визуализируем, немножко вспоминаем, как это выглядит. Графы могут быть неориентированными, могут быть ориентированными, могут иметь веса, например. Ребра у графа могут иметь веса. Вершины могут тоже иметь какие-то веса. Например, там может храниться какая-то информация, которую мы будем класть во время оплода графа. Могут иметь разные компоненты связности, то есть нецельный граф может быть. Могут иметь циклы. В ноду может входить и выходить разное количество...
рёбер. то есть в целом возможны любые комбинации, которые нужно примерно держать в голове. так, сейчас прошу прощения, буквально 5 секунд. да, извиняюсь за задержку, просто у меня в трансляции огромная задержка и я не понимаю, на каком слайде я сейчас нахожусь. так, прошу прощения, сейчас мы на седьмом слайде. то есть вы видите картинку. так, да, еще раз приношу извинения, но пока не получается. так, давайте перейдем к рассмотрению первой задачи. так, я думаю, пойдет лучше. я буду просто смотреть свою презентацию тогда. итак, у нас задача. find a town village. начнем с первой несложной задачи. подберем условия. то есть у нас есть город и есть n человек, они пронумерованы от одного до n. нам нужно найти так называемый town judge. данное условие. town judge никому не доверяет, условие номер один. все, кроме него, доверяют ему. а также нам известно, что существует только один человек, который удовлетворяет условия 1 и 2. это условие 3. нам дан массив, называется в котором есть по сути соответствия a и b на позиции i, что означает, что человек a i доверяет человеку b i. нам нужно найти, существует ли такой town judge, а если нет, вернуть минус единицу.
Подумаем, как вообще можно это представить, визуализировать, то есть это не что иное, на самом деле, как граф. То есть структура связи между людьми в этом городе – это просто-напросто граф, где вершины – это люди, а trust или нет, то есть доверяет он или нет – это, по сути, ребро в этом графе. Что нам здесь требуется найти? Нам нужно найти такую вершину, в которую входит n-1 ребер, правильно? Потому что все, кроме джаджа, все, кроме судьи, ему доверяют, то есть это n-1. А также нам известно, что сам этот таунт-джадж никому не доверяет, то есть выходить будет ровно 0 из этой вершины. То есть у нас здесь получается directed graph, то есть граф с направленными ребрами, и нам нужно найти вот такую вершину, удовлетворяющую этим условиям. Подумайте, ну, то есть задача нам понятна – это просто такой простой обход графа и проверка. Давайте так и запишем, что нам нужно. Нам нужно иметь в виду, сколько выходит ребер, для простоты сделаем два массива, сколько выходит ребер и сколько входит. Размер, у нас надо учесть просто еще условия задачи. Люди пронумерованы в 1 до n, поэтому у нас массив будет до n плюс 1, а первое значение нулевое, то есть в питоне это будет первое значение нулевое по индексу, мы обозначим как минус бесконечность. Это просто, чтобы удовлетворить условиям задачи и сократить иф-элсы, мы не будем писать дополнительные иф-элсы, чтобы корнер-кейсы, когда, например, нам подадут какой-нибудь там пустой массив или массив с одним человеком, такие неинтересные случаи, мы аккуратно закроем сразу вот таким способом. Теперь далее, давайте подумаем, вот у нас есть эти массивы, которые мы хотим заполнить, как мы будем их заполнять? Ну, очевидно, что надо просто пройтись по всем элементам массива trust и собрать оттуда информацию, правильно? Пока что ничего сложного, просто двигаемся, и мы знаем, что по условию первый элемент доверяет второму, так и записываем то, что из первого, значит, индекса выходит.
ребро мы прибавляем, а во второй индекс оно входит, соответственно, в out массив мы пишем плюс один, в in массив мы пишем плюс один на j, в out массив пишем плюс один на i, а в in массив пишем на j. Думаю, здесь достаточно все прямолинейно, проще увидеть, мне кажется, глазами, чем сказать это словами, на самом деле. Пока что все просто. Далее, давайте подумаем далее. То есть мы заполнили наши эти два массива и остается проверить, что. Вспоминаем условия. Нам нужно найти людей, точнее, одного конкретного человека, джаджа, который доверяет двум условиям. Когда он никому не доверяется сам, а все доверяют ему. Что это значит? Что массив out degree должен содержать ноль, он никому не доверяет. Массив in degree должны доверять все, кроме него. То есть n-1. Все очень просто. Проверяем, пробегаемся по всем нашим людям. Это k in range n-1 и простой if. Здесь не нужно беспокоиться уже даже о нуле будет, потому что мы заранее уже обсудили на строках 6 и 7 у нас стоит эта заглушка. Возможно, можно заметить еще, что в целом не обязательно иметь здесь два массива. Для аккуратности, для наглядности можно иметь два массива и понятно, что на алгоритмическую сложность не повлияет, но в целом от одного массива можно избавиться. Предлагаю внимательным слушателям подумать об этом после трансляции, можно ли обойти здесь одним массивом. Но, конечно, на алгоритмическую сложность это не повлияет. Так, это была наша такая разминочная задача. Давайте начнем что-нибудь более интересное. Вспомним, как графы могут обходиться, как можно обходить графы. По сути, два способа. Breadth-first search и depth-first search. Думаю, они знакомы слушателям. Breadth-first search очень просто. Мы начинаем из вершины 1, то есть визуализация здесь такая. Номер вершины – это номер, по которому она попадет в исходный массив, если мы сохраним массив, когда обойдем весь граф. То есть мы начнем с вершины 1, 2, 3, 4, 5, 6, 7, 8, 9 именно в такой последовательности. То есть грубо говоря, мы...
как будто так разрастаемся по нашему графу во все стороны. то есть дерево, кстати, это тоже такой же граф, как и любой другой. можно представить на примере структуры дерева такого. как выполнить такой алгоритм? опять же, классическая реализация. нам нужна очередь. мы кладем в эту очередь нашу вершину, root, строчку номер 4. прошу прощения, вот 15 слайд. у нас есть вершина q и вершина... у нас есть очередь q и вершина root. кладем в очередь q вершину root и дальше, пока она не пустая, у нас шаг алгоритма. как выглядит этот шаг? мы берем из этой очереди первую вершину. здесь еще, прошу прощения, добавлено 7, 8, 9. можете, по сути, проигнорировать эти строчки. можно сразу перейти к десятому. то есть что мы делаем? мы просто итерируемся по всем соседям вершины v и проверяем. если эта вершина еще не была просмотрена, то добавляем ее в очередь. и очевидно таким образом, что мы каждый раз пойдем в конец, забираем из начала и таким образом мы расходимся как бы вширь, грубо говоря, интуитивно, если это подумать. такой алгоритм может быть полезен, если мы решаем какие-нибудь задачи. вот если вы видите условие задачи какой-нибудь в духе, какое будет кратчайшее расстояние от здания до моста, например, и так далее. очевидно, что... заметить нужно следующее, то что алгоритмическая сложность у алгоритмов breadth-соседщих и depth-соседщих, конечно же, одинаковая. в общем, в лучшем случае им всем нужно будет обойти весь граф. это неизбежно. то есть ни один алгоритм не лучше другого в этом смысле, не оптимальнее. но он может быть лучше для конкретных задач с точки зрения среднего какого-то времени выполнения. поэтому разумно на практике, если вас просят сделать задачу найти кратчайшее расстояние от чего-то до чего-то, использовать breadth-first search, а не depth-first search. но опять же, это уже какие-то практические реализации. дальше мы по презентации посмотрим, какие могут быть примеры.
посмотрим на второй вариант обхода графа depth-first-search. Из названия понятно, что depth-first – идем в глубину, то есть 1, 2, 3, все, это leaf node, у нас дальше ничего нет, возвращаемся в рекурсе на один шаг назад, двойка, четверка, возвращаемся на два шага назад, единица и так далее. То есть мы каждый раз идем максимально в глубину, пока все вершины у нас не будут потрачены. На мой взгляд, это более, может быть, простой алгоритм, хотя на самом деле оба они простые, конечно. Но здесь он записывается совсем легко, как это выглядит. Просто ходим по всем нашим соседям w из вершины v, и если эта вершина еще не была проверена, рекурсивно вызываем ту же функцию. Вот и все. То есть нужно просто держать где-то массив в каком-то виде, хранящий уже посещенные вершины, и рекурсивно вызывать ту же самую функцию, просто меняя аргумент, и все. Теперь давайте рассмотрим такое понятие, как топологическая сортировка, и вообще зачем она может быть полезна, и что это вообще такое. Да, действительно, пока что не очень сложно, надеюсь, сейчас станет чуть-чуть сложнее. Давайте рассмотрим топологическую сортировку. Что это такое? Это такое не совсем, может быть, формальное определение сортировки, то есть это скорее, наверное, если по-русски говорить, сортировка здесь, на мой взгляд, не совсем уместно, но это просто используется такое слово. Что нам нужно сделать? Нам нужно сделать так, визуально это можно представить, что граф расположен таким образом, что стрелочек назад или наверх, в данном случае, не существует, то есть они все направлены в одну сторону, то есть каждая вершина uv, если она была в нашем графе с точки зрения, что из u у нас идет ребро v, также они должны находиться в итоговом массиве. Как выглядит этот алгоритм? Здесь чуть больше строчек, но на самом деле ничего сложного тут нету. Что нам нужно сделать? Нам нужно создать некоторый массив L, в который мы положим все наши вершины.
и иметь некоторый массив, где мы будем помечать вершины как посещённые или как рассматриваемые в данный момент времени. Питон тут при чём? Поступил вопрос. Питон тут, наверное, при том, что реализация алгоритмов выполнена задачей, точнее, решение задачи сделано на Питоне. Больше Питон ни при чём. Алгоритмы абсолютно индеферентны к языку программирования. Вы не можете писать на любом языке, но в данном случае задачи будут решены на Питоне. Так, вернёмся к топологической сортировке. Что мы делаем? Для каждой вершины, когда мы её вызываем, мы проверяем, есть ли у неё какая-то маркировка. Если это так называемый permanent mark, то всё нормально. Если это temporary, так называемый temporary mark в этой нотации, то значит, что мы нашли цикл. Сейчас станет видно почему. Потому что в строчке 14 мы двигаемся по всем соседям ноды N, то есть это, допустим, M в данном случае. И если мы снова увидим ту же ноду N, потому что она имеет temporary mark, это значит, что мы зациклились и нашли эту же самую ноду, с которой начали. Поэтому мы делаем такие пометки. Но если мы не зациклились и закончили этот цикл на строчке 16, то тогда можно добавить permanent mark и положить эту ноду N в пассив. Рассмотрим на примере, возможно, так будет чуть понятнее. В данном случае простой пример. Мы дойдём до самого конца графа. Если мы начали, не важно, с какой ноды мы начинаем на самом деле, из A или D, дальше мы увидим почему. Мы дойдём до конца и положим F. Затем, если мы начинаем, например, A, B, E, F. Вступил комментарий, что, возможно, вы не видели слайд, прошу прощения. Надеюсь, будет понятно по объяснению словами, а дальше мы увидим, как это в Python сделано в любом случае. Так, сейчас 19 слайд, мы видим E и F. B, то есть мы, грубо говоря, отматываем наш путь назад.
Теперь вопрос на засыпку. Какую следующую вершину мы там увидим? Допустим, мы начали из вершины А. То есть мы начали А, Б, Е, Ф. Ф это была конечная вершина, мы ее положили. Передней была Е, передней была Б. Теперь вопрос, какая будет следующая вершина в этом графе? Очевидно, ответ С, потому что А – это вершина, по которой еще идет цикл ФОР. Поэтому мы вначале положим вершину С, а потом уже, когда вершин не осталось, и мы этот цикл проходим, переходим на следующую строчку в нашей функции, уже туда положится вершина А. И во внешнем цикле положится дальше вершина Д. Стоит заметить, что это один из вариантов, как могла сортировка случиться. Но могло бы идти иначе. Если бы мы начали с вершины Д, реализация была бы другой. То есть топологическая сортировка, она вообще говоря не уникальна. Например, на таком простом примере можно увидеть, что с одной стороны граф можно было развернуть А, Д, С, Б, с другой стороны можно было его развернуть А, С, Д, Б. И то, и то это была бы валидная топологическая сортировка, то есть она не уникальна. Нужно иметь это в виду. И также очевидное следствие то, что во время сортировки мы автоматически проверяем граф на наличие циклов. Если они там есть, то мы его по сути отсортировать в этом смысле не можем. Давайте сейчас решим задачу, где этот алгоритм нам очень пригодится. Называется Course Schedule 2. У нас есть массив NumCourses. Это курсы, которые как студенту надо нам пройти. Они пронумерованы от нуля до, давайте назвать это n-1. И у нас есть некоторый массив пререквидитов, то есть что нельзя, например, курс 3 взять, не взяв курса 2. Или наоборот. Любого вида пререквидиты А и Б, которые говорят, что курс Б можно взять только если мы уже прошли курс А. Нам даны два такие величины.
количество курсов и массив пререквизитов. И нас просят вернуть последовательность этих курсов, которую студент мог бы, грубо говоря, взять, выучить. А если нету такой последовательности, то возвращаем пустой массив. Отсюда сразу очевидным становится, что это не что иное, это практическая сортировка ведь, правда? У нас есть связь между курсами, что зачем надо брать, это не что иное, уже очевидно, как граф. И у нас есть задача взять этот ордеринг, то есть это сортировка некоторая. И также третий очевидный пункт, что если нету валидных ответов, то это значит, там есть цикл, и нам нарочно дали такой граф, который не имеет смысла в практическом смысле для студента, но имеет смысл с точки зрения алгоритмов. Так, как это можно решать? Понятно, нам надо вначале составить граф. Здесь, например, граф можно составить таким образом. Это просто будет у нас матрица такая, массив массивов, потому что они просто пронумерованы числами. Здесь в этой задаче можно будет написать вот так. Сразу обозначим наш массив курса, с которым мы положим все ответы и вернем его. И для топологической сортировки нам понадобится массив visited, в данном случае это хэштаблица для проверки, были ли мы уже в этой ноде или нет, какая у нее пометка. Заполним наш граф. Тут все довольно просто. Просто идем по всем нашим преподитам i, j и говорим, что поскольку j нельзя выучить, не выучив i, так и положим. Graph i, append Graph j. Теперь подумаем, как дальше выглядит наш код. То есть у нас пока что есть граф, и есть некоторая идея, как мы хотим использовать топологическую сортировку здесь. Давайте для удобства просто выведем ее в отдельную функцию, а в этой функции мы просто ее будем вызывать, и она как-то у нас будет реализована, мы сейчас это отдельно обсудим.
Сделаем это в таком виде, то есть идем по всей длине нашего, как сказать, правильно, range, numcourses. Часто бывает удобно вызывать функции рекурсивные в таком виде. Мы знаем, что, возможно, ответа когда-то не будет, когда-то будет цикл в этом графе. Поэтому давайте так функцию и задизайним, что она будет вызывать, возвращая true или false. Если она возвращает false, это значит, что там есть цикл, а значит, что задача не имеет решения. В противном случае мы на 27 строчке возвращаем наш массив. Такой трюк часто бывает полезен в удобной компактной записи. Теперь давайте напишем, собственно, нашу функцию dfs, которая будет содержать еще и топологическую сортировку. Вспомним, что нам надо сделать вообще. Нам надо вначале проверить вершину, потом как-то обойти ее соседей, и в конце положить эту вершину в массив. Это три основные наши блока, которые надо заполнить. Вспомним, что у нас в алгоритме, в псевдокоде было permanent mark и temporary mark. В целом можно упростить и просто хранить оба марка в одном массиве, очевидно, visited. Там не нужно два для этого, две хэштаблицы для этого. Поэтому так и проверяем. Если и уже была visited, то мы просто возвращаем этот ответ. Там может быть либо true, либо false. То есть permanent mark — это будет true, temporary mark — это будет false. Temporary означает, что мы эту вершину как раз рассматриваем и зациклились. Permanent mark будет означать, что мы просто ее уже видели и все в порядке. Не нужно дальше вызывать функцию на том же самом значении. Теперь второй блок. Нам нужно пройти, вспомнил алгоритм, пройти по всем соседям и по сути сделать то же самое. То есть вначале мы помечаем вершину как посещаемую в данный момент. Дальше вызываем всех соседей. Дальше помечаем вершину как посещенную. Собственно, очень просто. Помечаем, что вершина данный момент false.
И идем по всем ее соседям g. Тот же самый трюк, используем вот эту удобную запись, что если нет, то значит false. Во всех остальных случаях нам это подходит, и мы пройдем на строчку 10. Просто вызываем точно так же рекурсивно, но у нас в аргументе вместо i теперь g. Мы идем по соседям. Если где-то i нам встретится в глубине этой рекурсии, то она попадет на строчке 4 и будет false. А если она где-то нам не встретится, то мы переходим на 10 строчку и говорим «все, окей, это теперь true». И нам просто остается положить этот курс под номером i в итоговый наш массив курсов и вернуть true. Думаю, не надо никому объяснять, что достаточно в питоне написать курсы с append i, и этого будет достаточно, чтобы... То есть не обязательно его возвращать, не обязательно его хранить как глобальную переменную. Здесь просто используем такие особенности языка питон. Надеюсь, это всем понятно. Если нет, дайте знать. Так, перейдем к третьей задаче. Вспомним... Точнее, не вспомним, коснемся такой темы — раскраска графа. Что такое раскраска графа? Это, может быть, вызывает разные значения. Одно из основных — это когда говорят про вершины, поэтому про это и остановимся. То есть нужно присвоить такие цвета вершинам графа, чтобы две вершины, которые имеют ребро, то есть по сути соседи, они обязательно имели разные цвета. То есть не может быть такого, что мы из зеленой вершины переходим в зеленую. Такого быть не должно. И задача, которая ставится, классическая задача — найти хроматическое число, минимальное число цветов, необходимое для раскраски графа. Это классическая задача, которая на самом деле довольно сложна в решении, мягко говоря. Мы не будем сейчас касаться именно какой-то теории здесь, а рассмотрим один конкретный вариант, как можно это делать. Можно раскрашивать вершины просто жадным образом. Берем первую вершину, ставим ей наш цвет красный. Дальше идем по всем ее соседям.
что-то доступное еще из цветов, берем этот цвет, а если нету, то добавляем новый цвет в массив, и таким образом, жадным способом, из любой первой вершины начинаем раскрашивать граф. Очевидно, что такой алгоритм нам не даст это оптимальное число. Давайте, например, возьмем такую картинку, что у нас есть по сути две компоненты связанности в графе. Точнее, не две компоненты связанности, но можно разбить граф так визуально на две части. И вот, например, такая раскраска. Давайте задумаемся, если мы раскрашиваем граф жадным алгоритмом, приведет ли это обязательно к оптимальному решению? На самом деле, конечно, ответ нет. Жадный алгоритм не гарантирует раскраску графа за наименьшее возможное хроматическое число хи, но, тем не менее, на практике он может быть нам полезен, поскольку, очевидно, что он просто линеен, мы берем первую вершину и дальше начинаем жадным образом раскрашивать граф. Посмотрим, где это может пригодиться на практике. Такая задача виседывания Possible Bepartition. По сути, по-русски можно сказать разделение на две части. Задача звучит так. У нас есть группа из n человек, поднумерованных от 1 до n, и нам требуется понять, можно ли их разбить на две группы. Группы могут быть любого размера. Нам дан массив dislikes, то есть a i, b i. Это означает, что a i не любит человека b i. Dislikes. Наверное, можно так перевести это слово, как не любит. И нам нужно так разбить людей, чтобы не было в одной группе тех, кто dislikes друг друга. Думаю, по условию все понятно. То есть, еще раз, у нас есть массив, который показывает, кто кого не любит, и нам надо разделить так, чтобы в одной группе не любящих друг друга людей не было. Так можно решать такую задачу. Но, опять же, очевидно сразу становится, что это задача на граф, поскольку у нас есть вершины и ребра, есть какая-то структура, есть какая-то связь, компоненты вот такие. Значит, сразу нам намек уже, что...
что это что-то на графе. bpartition, опять же, довольно очевидно, становится, что это просто-напросто раскраска. теперь, вот мы знаем, что есть жадная раскраска, но она не гарантирует никаких оптимальностей. давайте подумаем здесь, можем ли мы использовать такой алгоритм. представим, что, допустим, можем. обозначим в северной коде некоторым в голове, что если мы раскрасили первого человека каким-то цветом, поскольку здесь цветов всего два, то очень легко доказать и понять, можно это сделать или нет. допустим, мы раскрасили его цветом номер один, и дальше начинаем раскрашивать в поисках возможности этого сделать. допустим, эта возможность есть. вторая ситуация, мы раскрасили человека цветом два, поскольку эта возможность была, очевидно, что и снова решение будет. и очевидно, что эти решения будут абсолютно симметричными, просто инверсированными друг к другу. то есть абсолютно неважно, с какого цвета мы начинаем, можно начать с любого цвета. поскольку так, то можно жадным образом раскрашивать и найти, проверить наличие этого решения. так, мы примерно поняли, как мы хотим это сделать, давайте перейдем к реализации. граф в данном случае давайте представим в виде словаря, где у нас ключами будут вершины, а значениями массивы, лист в бетоне, и будем хранить хэштаб лицу colors, куда будем класть наши цвета. теперь положим в наш граф, то есть сформируем наш граф. мы знаем, что массив dislike означает «человек и не любит человека жи». очевидно, что 28 строчка, думаю, не вызывает вопросов, мы просто по смыслу кладем, как написано. есть 29 строчка, вот здесь я предлагаю слушателям внимательно подумать, почему мы вообще это делаем. я сейчас не буду давать ответ, это оставлю, но подумать потом, что будет, если мы этого не сделаем. давайте сейчас обсудим решение и предлагаю всем подумать, что будет, если мы этого не сделаем.
опять применяем тот же трюк, он часто бывает полезен, как всегда, если есть какой-то depth search, просто проходим по всему нашему графу, и если эта вершина еще не была рассмотрена, то есть она еще не лежит в colors, вызываем нашу реперсивную функцию, которая будет проверять и раскрашивать граф, если она возвращает false, то это значит false, а если она закончила свое выполнение, в конце возвращаем true, пока что все понятно, теперь давайте подумаем, как ее можно выполнить, мы уже обсудили, что задача симметричная, нам не важно, с какого цвета начинать, поэтому давайте начнем с некоторого цвета A, вызываем вершину, если она еще не была рассмотрена, то пометим ей цвет A, из-за симметричности задачи это абсолютно неважно, теперь да, что нам нужно дальше сделать, нам надо пройтись по всем соседям и как-то вызвать ту же самую функцию, которая будет снова это проверять, но тут есть какие-то уже нюансы возникали, мы не можем просто так вызывать в тупую depth search, тут надо немножко уже подумать, конкретно 11 строчка if in graph, если возникли вопросы, она нужна лишь для того, чтобы не изменять наш массив граф, наш дикт граф, в питоне такая реализация дефолт дикта, что если вы вызовете несуществующую вершину, он добавит ее с пустым значением, и это сломает код, это просто техническая такая заглушка, поэтому не обращайте внимания, основной смысл в коде начинается с ручки 12, мы идем по нашим соседям и очевидно, что есть два варианта, когда наша вершина G еще не была рассмотрена и она отсутствует в массиве colors, либо когда она уже была рассмотрена и уже есть в этом массиве, нам нужно подумать, как мы заполним эти две ветки решения, очевидно, что если она была уже в colors, то остается просто проверить ее цвет.
Правда ведь? То есть если этот цвет, например, у вершины i цвет i, а у вершины g цвет тоже i, то это нам не подходит. Это интуитивно понятно. Если она не была в colors, опять же, из очевидных интуитивных соображений, поскольку алгоритм жадный, мы просто присваиваем ей другой отличный цвет от вершины i. Давайте сделаем такой color mapping из a в b, из b в a. Просто для удобства будем хранить маленькую хэштаблицу, которую будем раскрашивать наши вершины. Вернемся снова в наш алгоритм. Идем по всем соседям. Смотрим, есть ли эта вершина уже в массиве colors. Раз ее там нету, жадно присваиваем ей другой цвет. И рекурсивно вызываем функцию из этого же, теперь уже из новой вершины g. Пока все понятно. Осталось заполнить, что будет, если мы уже вершину g встретили. Но здесь, я думаю, еще проще. Если цвета совпадают, значит мы, к сожалению, не можем разбить людей на две группы. Нужно ли делать здесь что-то еще? Давайте подумаем. Если мы здесь заново будем вызывать рекурсивную функцию, что тогда случится? Очевидно, что будет бесконечный цикл. Потому что раз вершина g уже есть в colors, значит мы ее уже вызывали. И вызывать на ней заново depth first search не нужно. Соответственно, здесь, в этом куске, нам тоже больше ничего не нужно. Вызываем рекурсивную только тогда, когда она не была еще раскрашена. На строчке 15. Вот, собственно, и все. Не знаю, там в чатике кто-то может сказать, зачем нам нужно было делать на слайде 41. Давайте вернемся на него. На слайде 41, на 29 строчке, класть в g также i, несмотря на то, что вообще-то нас спросили, что i не любит g. Не знаю, если кто-то в чатике говорит, давайте посмотрим. А, молча. Ну что ж, ладно.
Тогда не буду давать ответ. Надеюсь, потратите 5 минут после вебинара и подумайте, зачем мы это здесь делали. Да, давайте еще дадим немножко времени. Рассказалось бы, у нас задача была про directed graph, а мы ее, вообще-то говоря, вернули в описании как undirected. То есть была направленность в ребрах, мы ее взяли и убрали. Кажется, что мы делаем что-то не то. Но подсказка такая, что алгоритм-то работает, значит, мы делаем то. Ну что ж, давайте перейдем дальше. Кому интересно, могут после вебинара подумать над этим. Давайте перейдем к четвертой теме, которая будет называться «Пути в графах», и разберем здесь один из алгоритмов. Называется алгоритм Дейкстра по-русски. Пути в графах — это очевидная из названия, это последовательность посещения вершин каких-то, правильно? Часто возникает задача найти какой-то кратчайший путь. Например, где угодно она может возникать, например, даже в программировании, в компиляторах возникает. Кратчайший он может быть чаще всего во взвешенном каком-то графе. Это наиболее интересная издача, потому что есть иначе довольно понятные решения у задачи. Чаще всего граф взвешенный, то есть ребра имеют некоторые веса, и мы хотим найти в этом графе кратчайший путь. Алгоритм Дейкстра решает его следующим образом. Давайте я сейчас попробую описать это, может быть, немножко интуитивно. Вы, если хотите, следите за псевдокодом. Мы хотим сделать следующее. Мы хотим из начальной вершины начать наш алгоритм. На первом шаге мы говорим, всем вершинам присваиваем бесконечно большое значение, которое описывает расстояние от этой вершины до всех. И дальше начинается наш алгоритм.
На каждом шаге мы берём самую близкую вершину, то есть мы храним в некотором массиве вершину и расстояние до неё от начальной. И мы берём самую близкую на каждом шаге. То есть это алгоритм, Жанна, мы берем самую близкую вершину. Из этой близкой вершины мы проверяем всех её соседей и смотрим, какое до них расстояние из этой вершины. Если так получается, что где-то можно обновить и уменьшить это расстояние, то мы это делаем. Это строчка 12, получается, в псевдокоде. То есть ещё раз, мы на каждом шаге берём вершину с кратчайшим расстоянием, из этой вершины проверяем всех её соседей и обновляем расстояние, если нужно. И дальше снова выбираем самую ближайшую вершину, снова проверяем расстояние до её соседей, если где-то можно улучшить расстояние, мы его улучшаем и снова переходим, пока не закончатся все наши вершины. То есть алгоритм Жанна, он берёт на каждом шаге кратчайшее расстояние, вершину с кратчайшим расстоянием, и мы двигаемся, пока не найдём нашу финальную вершину. Давайте разберём это на примере. Станет, мне кажется, понятнее, если ещё непонятно. Допустим, у нас есть такой довольно запутанный граф, вершины пронумерованы, мы хотим попасть из вершин 1 в вершину 6. И есть некоторые веса, пути, по которым мы можем туда попасть. Первое, инициализация алгоритма. Мы говорим, что все вершины имеют бесконечно удалённое расстояние от вершины 1. Окей. Посмотрим, то есть начинаем наш шаг теперь, положили вершину 1 в наш массив, и начинаем шаг алгоритма. Посмотрим, какие расстояния из вершины 1 до соседних вершин. Из вершины 1 мы можем попасть в 2, 3 и 4. И мы видим, по каким стоимостям, с какими весами можем туда попасть. Очевидно, что всё меньше бесконечности. Обновляем. Следующая. Следующая самая дешёвая вершина. Вершина 3 с весом 1, который, к сожалению, немножко попал под синюю линию.
вес 1 — это самая ближайшая вершина из текущих, из всех имеющихся. берем ее и обновляем расстояние, которое есть из вершины 3 до соседних вершин. куда мы можем попасть? можем попасть в вершину 4, 5 и 6. проверяем, за какую цену, например, мы можем попасть в вершину 4. это вес, это расстояние, которое было до вершины 3. это единичка, мы ее храним тут рядышком. и 5. суммарно получается 6. но с другой стороны, мы уже знаем, что мы можем попасть за 4 монеты из вершины 1, что дешевле. поэтому не обновляем. вершины 5 и 6 обновляем. следующая самая ближайшая вершина — 2. в нее была цена 2. смотрим по аналогии абсолютно так же, куда из нее можно попасть. вершина 4 и 5. 4 ему снова дороже получается. 2 плюс 7, чем 4. а в пятую вершину можно попасть за 2,5 плюс 2, за которое мы попали в двойку. это меньше, чем 11. отлично. значит, эту вершину надо обновить. какая следующая у нас будет самая дешевая вершина? это будет вершина номер 4. мы туда попали пока что за 4 монеты. смотрим, куда из нее можно попасть. абсолютно все то же самое. можем попасть в вершину 6 и все. обновляем или нет? 9? нет, не обновляем. то есть оставляем как есть. что у нас осталось? у нас осталась вершина 5 с весом 4,5. смотрим, куда из нее можно попасть. только в вершину 6. но и снова здесь получается дороже. да, давайте, ребят, напоминаю, что если в какой-то момент, может быть, мы идем быстро или есть вопросы по предыдущей сдаче, то не стесняйтесь говорить. если все очевидно и все просто, то мы продолжаем. но в любой момент не стесняйтесь задавать абсолютно любые вопросы. это, конечно, важно.
очевидная вводная вещь. Итак, мы обновили все наши вершины, и это конец нашего алгоритма. Мы знаем, за какую стоимость из вершины 1 мы можем добраться в вершины 2, 3, 4, 5 и 6. Например, если была задача найти в 6, мы знаем, что можно добраться за 5 монет. Резюмируем. Что нам позволяет этот алгоритм? Он позволяет нам найти кратчайший путь от задней вершины до всех остальных. Алгоритм жадный, поскольку мы на каждом шаге выбираем самую ближайшую вершину. И третье свойство – он работает только для графов с положительными весами. И здесь вопрос внимательным слушателям – почему этот алгоритм работает только для графов с положительными весами? Казалось бы, почему мы не можем его запустить, если вес, например, был отрицательный? Пока что в том описании, которое я дал, нигде, на первый взгляд, это условие не требовалось. Мы просто брали ближайшую вершину, смотрели, как из нее добраться, за какой стоимость, и обновляли, если это было дешевле. Почему же я тогда говорю, что этот алгоритм работает только с положительными весами? Предлагаю всем подумать и дать ответ в чатик. Я верну картиночку на минуту с нашими путями. Здесь они все были положительными, но, допустим, не знаю, для примера, путь 2-5 был минус 2,5. На что бы это повлияло? Или был бы минус 10? Жду ответов в чатике. Давайте подумаем, почему только положительные веса. Давайте возьмем минутную паузу и дождемся ответа.
я пока немножко, может быть, покажу вам пару раз шаги алгоритма так, боюсь, реакциями тут не отделаешься, нужен ответ ответ здесь нужен, потому что это, если вы знаете ответ на этот вопрос, то по сути вы поняли этот алгоритм, а если что-то здесь непонятно, почему это только положительное веса, значит алгоритм все же остался непонятен, поэтому я хочу, чтобы сейчас все подумали и дали ответ, он на самом деле очень простой давайте я тогда дам ответ сам, к сожалению, вспомним еще раз наш алгоритм мы берем каждый раз самую ближайшую вершину и из нее находим расстояние до других вершин что мы делаем дальше? мы снова берем самую ближайшую вершину и находим расстояние до ее соседей теперь представим, что у нас на первом шаге расстояние 1, 2, 3, мы их обновили, взяли вершину, там снова 1, 2, 3 или там 5, 4, 6 какие-то расстояния, мы их обновили, заново берем вершину, а там расстояние минус 100, но она оказалась не самой ближайшей или наоборот, допустим, она была самой ближайшей, но мы взяли ее с отрицательным весом и очевидно, что из-за жадности алгоритма это будет уже не оптимальное решение, этот алгоритм работает только потому, что все положительное, он жадно выбирает каждый раз ближайшую вершину, а а плюс б плюс с будет минимально, когда а минимально, б минимально и с минимально в положительном смысле, если что-то из этого выросло, то и сумма выросла
Только за счет этого алгоритмы работают. Если у нас будут отрицательные веса где-то, если b отрицательный, a плюс b плюс c, и там b что-то в минусе, то весь алгоритм, вся эта жадность его здесь ломается. Потому что жадные алгоритмы, они нам ничего не гарантируют. Только в определенных ситуациях, в определенных случаях. Так, давайте вернемся теперь снова к нашему алгоритму. Из чего складывается время работы этого алгоритма? Вот эти две вещи. Нам нужно найти эту ближайшую вершину и обновить расстояние. Это так называемое время ревоксации. Как это можно сделать? Самая какая-то очевидная, самая простая вещь, которую можно сделать, это просто обойти все вершины и обычным, самым простым способом переназначать расстояние. Тогда это будет на каждую операцию тратиться o от v и o от 1 соответственно, константное время. Но при этом, поскольку вершина у нас тоже v, для каждой нужно это совершить, это будет v квадрат. И каждый раз ревоксацию совершать для всех ребер у соседей, это e. То есть в суммарной сложности v квадрат плюс e. Можно ли как-то сделать иначе? Самый оптимальный способ, как это можно сделать, это использовать так называемую фибоначевую кучу. Она позволяет нам находить самую дешевую вершину за лог v, за логарифм. И сохраняет тоже свойства ревоксации o от 1. Но на практике, если честно, такого я нигде не встречал. Это скорее может быть интересная теоретическая вещь. На практике можно думать это с точки зрения двоичной кучи. И здесь тогда с множеством алгоритмов будет лог v лог v. И в суммарной сложности по сути будет v плюс e на лог v. Это более практичный и, мне кажется, все время реализуется именно с таким способом. Рассмотрим последнюю задачу, которую использует алгоритм. Cheapest flights within k stops. У нас есть массив flights. Так, 70 и все правильно. Который выглядит так. Из в цена. From to price. Который говорит нам о том, что из какого города в какой можно перелететь, за какую цену прямым перелетом. Все просто. Ставится вопрос, что мы хотим попасть из города СРЦ в город ДСТ.
и совершить при этом не более K-пересадок. Это наше ограничение, K-пересадок. И нужно в этих условиях найти самый дешевый маршрут. То есть самая минимальная цена, которая нам нужна, чтобы заплатить за эти билеты. Например, посмотрим на такой простой пример. Нам надо попасть из 0 в 3. С одной стороны можно лететь 0, 1, 3, но это займет 700 рублей. А если лететь 0, 1, 2, 3, это займет 400. И допустим, если K у нас равно 1, то, к сожалению, придется лететь за 700. Но если K равно 2, то можно лететь за 400. Соответственно, в зависимости от этого наш оптимальный маршрут в зависимости от K будет меняться. Как решать такую задачу? Ну, очевидно, что раз нам что-то нужно найти, какой-то путь за какую-то минимальную цену с какими-то ограничениями, очевидно, алгоритм Dijkstra здесь прямо идеально ложится. Что нам нужно? Нам нужно составить наш массив, граф, как обычно. Давайте сделаем его здесь в виде default dict. Положим начальную город в ключ, а в значение положим города, в которые можно попасть отсюда, и цену, за которую можно попасть. Все очень просто. Храним кэш-таблицу visited и нашу кучу, возможно, здесь я ее не очень удачно назвал, как queue, как очередь, это будет куча у нас. В нее мы кладем, по сути, цену, количество пересадок, которые мы совершили, чтобы туда попасть, и, собственно, саму эту ноду. То есть на первом идет у нас цена пересадки, нода начальной вершины, мы там бесплатно находимся, пересадок никаких не совершали, поэтому 0.0 src. Теперь начинаем наш обход. Вспоминаем алгоритм дейкстра. То есть мы, грубо говоря, инициализировали наши вершины. Какой у нас здесь будет шаг алгоритма? Пока очередь не пуста, достаем из этой кучи текущую ноду. Текущую, это значит самую дешевую. Цена, кост, остановки столбов.
и сама вершина нод. Пока все понятно. Теперь, на мой взгляд, самая интересная часть этого алгоритма, самая, может быть, не совсем очевидная часть этого алгоритма. Проверим, что количество остановок, количество пересадок стопс, которые мы совершаем в этой самой ближайшей остановке нод, больше ли оно того, что мы уже знаем в массиве visited. Думаю, не надо пояснять эту запись. visited, getNode, floatInf. То есть, если этой ноды не было, мы достанем бесконечно большое число. И если количество пересадок, которые мы здесь достали на девятой строчке, больше, чем то, что мы уже видели, то мы делаем continue. То есть пропускаем эту комбинацию cost, stop, snot. Вопрос, зачем мы так делаем? Потому что нигде, казалось бы, в том алгоритме, который я рассказывал, такого не было. А здесь зачем-то мы начинаем что-то проверять. Давайте снова вспомним наш алгоритм. Берем первую вершину и дальше берем все расстояния, обновляем и снова берем самую ближайшую вершину, обновляем расстояние, берем самую ближайшую вершину, обновляем расстояние. Наш жадный алгоритм, который здесь работает, потому что цена за билет всегда положительная, доплачивать за перелет никто нам не будет. Зачем же мы здесь вводим какой-то еще visited? Давайте снова я возьму одну минуту наподумать. Надеюсь, что сейчас активность будет чуть выше.
Так, все еще ждем ответов. Ставьте какие-нибудь комментарии, плюсики, если нужно время, или минусики, если вы хотите узнать ответ. Так, ну что, плюсики-минусики появились. Так, плюсик, то есть кто-то еще хочет подумать, отлично-отлично. Напоминаю, плюсик – это на подумать, а минус – на ответ. Хорошо, давайте перейдем дальше. Зачем нам это здесь нужно? Чтобы более внимательные слушатели могли заметить в псевдокоде этот массив, я его не упомянул, но он там был. Это нужно, чтобы проверять, что вершина не была рассмотрена для наличия проверки циклов, потому что иначе мы можем попасть в ситуацию, когда есть какие-то два города с дешевыми перелетами, и мы между ними можем просто зациклиться и постоянно выбирать самый дешевый очень долго. А также, потому что куча гарантированно нам достает самый дешевый, и здесь важно знать, помнить то, что если есть две вершины с одинаковыми костами, если каким-то образом туда попали, даже забудьте вообще, как это могло случиться, но если такое случилось, и у них одинаковый кост, но разный стопс, то всегда в начале библиотека heap q даст нам то, что при прочих равных, если кост при прочих равных, где минимальный стопс. Если стопс минимальный, то дальше, но дальше у нас уже нет.
она идет по аргументам нашего тапла и сортирует по каждому аргументу. Поэтому здесь мы можем не беспокоиться об этом, проверить токен на цикл. Мы знаем гарантированно, что мы выбираем самую дешевую вершину и с наименьшим количеством пересадок. Это просто из-за особенной стерилизации вот этой библиотеки heapq. Она уже нам прямо из коробки дает такое решение. Теперь мы взяли самую дешевую вершину с какими-то пересадками. Давайте ее проверим. Та ли это вершина, в которую нам надо? И сколько мы сделали пересадок? Если оба эти условия выполнены, то возвращаем стоимость. Мы нашли ответ. Если нет, что нам остается? Положить эту вершину с этим количеством остановок для проверки цикла на строчке 10 и пройти по всем соседям, положить их снова heapq в нашу кучу. Вводим теперь cost плюс price, то есть из этой вершины сколько добраться до следующих. Мы берем текущий cost и добавляем price, цену билета на перелет из этой вершины. Делаем одну пересадку, поэтому stop плюс 1. И neighbor — это наша новая вершина. Посмотрим еще раз на лейтенант целиком. Что мы делаем? Мы берем самую дешевую вершину. cost — самый дешевый, stop — второй элемент, которым сортируется. Проверяем на цикл. Проверяем, что мы нашли эту вершину. Кладем ее в оси visited. И проходим по соседям. Ничто иное, как алгоритм Dijkstra в прямом его, по сути, исполнении, с небольшим, может быть, отклонением с точки зрения этого stops visited. Но на самом деле, по сути, прямое исполнение этого алгоритма позволяет найти решение в такой задаче. Так, по сути, мы закончили с четырьмя задачами, которые мы хотели сегодня рассмотреть, которые у меня были готовы, по крайней мере. Дальше давайте я скажу пару слов про курс. То есть мы коснулись здесь сегодня графов, и на самом деле смотрели их не целиком. Из графов мы мало разобрали breadth-first search. Например, в предыдущей задаче,
мы могли решать бред в Сочи, на самом деле, если бы как-то еще запрюнили его аккуратно, то, может быть, и прокатило бы. Но, говорит, на Дейкстре, мне кажется, здесь ложится более красиво и более как-то интересно, что ли. Но, тем не менее, мы не коснулись неперераздач, связанных с бредом, с дебсом в Сочи и кучи еще других тем, которые есть в курсе, поэтому настоятельно рекомендую его рассмотреть. Что здесь можно сказать? В целом, могу по своему опыту сказать, что такие задачи, они могут казаться не очень практичными, что ли, но на самом деле это очень помогает писать код эффективно, чисто, понятно и не только вам, но и другим людям. Надеюсь, это, может быть, стало чуть понятнее после этой презентации. Поэтому не только это помогает проходить собеседование, но на самом деле помогает стать лучше как разработчику. Без этого, на самом деле, я убежден, что невозможно вообще. Примеры каких-то тем, которые будут в курсе. Различные алгоритмы, сортировки деревьев, жадные алгоритмы, трудные алгоритмы и так далее, и так далее. Из преподавателей два человека Степана Мацкевича и Марии Гордиенко. Послужные заслуги можете увидеть на слайде. Чуть подробнее про то, как проходит курс. Там есть видео лекции, которые можно смотреть в любом, по сути, последовательности. Какие-то практические задания, связи с преподавателем, а также комьюнити студентов, преподавателей, проверка заданий и так далее, полное погружение в курс. Так, что еще можно сказать? Есть QR-код, который дает скидку 30% до 31 августа. И превьюшка следующего вебинара через одну неделю про собеседование и разбор типичных ошибок.
Последний слайд, как обычно, слайд с вопросами. Предполагаю, что вопросов не будет. Для отрицательных... Да, хороший вопрос. Для отрицательных причин есть алгоритм, например, алгоритм Беллман-Форда, который мы здесь не рассматривали, но который есть в курсе. Так что еще одна хорошая причина — пойти в курс. Еще какие-то вопросы есть? Нет. Тогда, думаю, можно заканчивать, если больше вопросов нет. Всем спасибо за внимание и увидимся на следующем вебинаре.